{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Anomalo vs Normal","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport shutil\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib import cm\nimport matplotlib.patches as patches\n\nfrom PIL import Image, ImageOps\n\nprint(\"Listo !!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-02T22:06:45.550862Z","iopub.execute_input":"2022-01-02T22:06:45.551118Z","iopub.status.idle":"2022-01-02T22:06:45.560104Z","shell.execute_reply.started":"2022-01-02T22:06:45.551090Z","shell.execute_reply":"2022-01-02T22:06:45.559277Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"info=pd.read_csv('../input/mias-mammography/Info.txt',sep=\" \")\ninfo.drop(columns=['Unnamed: 7'],inplace=True)\ninfo=info.loc[~info.REFNUM.duplicated(),:]\ninfo.loc[info.CLASS==\"NORM\",\"Tipo\"]=\"Normal\"\ninfo.loc[info.SEVERITY==\"B\",\"Tipo\"]=\"Anomalo\"\ninfo.loc[info.SEVERITY==\"M\",\"Tipo\"]=\"Anomalo\"\neliminar=info.loc[ pd.isna(info.RADIUS) & (info.Tipo!=\"Normal\"),:].REFNUM.to_list()\ninfo=info.loc[~info.REFNUM.isin(eliminar),:]\n\ninfo.index=info.REFNUM\ninfo.Tipo.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:04:20.496961Z","iopub.execute_input":"2022-01-02T22:04:20.497505Z","iopub.status.idle":"2022-01-02T22:04:20.518046Z","shell.execute_reply.started":"2022-01-02T22:04:20.497467Z","shell.execute_reply":"2022-01-02T22:04:20.517402Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"frec=info.Tipo.value_counts()\n\nfig=plt.figure(figsize=(7,5))\nplt.bar(frec.index,frec.values)\nplt.title('Distribución de imágenes',fontsize=15)\nplt.ylabel('Número de imágenes',fontsize=15)\nplt.xlabel('Categorías',fontsize=15)\n\nfor absoluto,categoria in zip(frec.values,range(2)):\n    pct=absoluto/frec.sum()*100\n    pct=round(pct,2)\n    plt.text(categoria-0.1,absoluto-8,str(pct)+'%',fontsize=12)\n    \nplt.savefig('Distribucion.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:04:28.868665Z","iopub.execute_input":"2022-01-02T22:04:28.869125Z","iopub.status.idle":"2022-01-02T22:04:29.109928Z","shell.execute_reply.started":"2022-01-02T22:04:28.869089Z","shell.execute_reply":"2022-01-02T22:04:29.109239Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"info_balanceado=info.drop(info.loc[info.Tipo==\"Normal\",:].sample(n=95,random_state=211).index)\ninfo_balanceado.Tipo.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:04:32.079556Z","iopub.execute_input":"2022-01-02T22:04:32.079986Z","iopub.status.idle":"2022-01-02T22:04:32.093486Z","shell.execute_reply.started":"2022-01-02T22:04:32.079951Z","shell.execute_reply":"2022-01-02T22:04:32.092610Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"frec=info_balanceado.Tipo.value_counts()\n\nfig=plt.figure(figsize=(7,5))\nplt.bar(frec.index,frec.values)\nplt.title('Distribución de imágenes',fontsize=15)\nplt.ylabel('Número de imágenes',fontsize=15)\nplt.xlabel('Categorías',fontsize=15)\n\nfor absoluto,categoria in zip(frec.values,range(2)):\n    pct=absoluto/frec.sum()*100\n    pct=round(pct,2)\n    plt.text(categoria-0.1,absoluto-8,str(pct)+'%',fontsize=12)\n    \nplt.savefig('Distribucion2.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:04:48.331359Z","iopub.execute_input":"2022-01-02T22:04:48.331628Z","iopub.status.idle":"2022-01-02T22:04:48.548154Z","shell.execute_reply.started":"2022-01-02T22:04:48.331597Z","shell.execute_reply":"2022-01-02T22:04:48.547451Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"i=1\nplt.figure(figsize=(8, 5))\nplt.suptitle('Imágenes de muestra',y=0.92,fontsize=15)\n\nfor tipo in [\"Normal\",\"Anomalo\"]:\n    \n    muestras=info.Tipo[info.Tipo==tipo].sample(n=1,random_state=11).index    \n    \n    for muestra in muestras:\n        \n        if tipo==\"Anomalo\":\n            \n            img_path=\"../input/mias-mammography/all-mias/\"+muestra+\".pgm\"\n            \n            cord_x=int(info.X[info.REFNUM==muestra])\n            cord_y=1024-int(info.Y[info.REFNUM==muestra])\n            radius=int(info.RADIUS[info.REFNUM==muestra])\n                        \n            img = cv2.imread(img_path)\n            \n            plt.subplot(1,2,i)\n            plt.imshow(img)\n            \n            ax = plt.gca()\n            rect = patches.Rectangle((cord_x-radius,cord_y-radius), radius*2, radius*2, linewidth=1, edgecolor='r', facecolor='none')\n            ax.add_patch(rect)\n            \n            plt.title(tipo)\n            i=i+1\n            \n        else:\n            \n            img_path=\"../input/mias-mammography/all-mias/\"+muestra+\".pgm\"\n            \n            img = cv2.imread(img_path)\n            plt.subplot(1,2,i)\n            plt.imshow(img)\n            plt.title(tipo)\n            i=i+1\n\nplt.savefig('muestras.png')            \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:14.444164Z","iopub.execute_input":"2022-01-02T22:05:14.444440Z","iopub.status.idle":"2022-01-02T22:05:15.214196Z","shell.execute_reply.started":"2022-01-02T22:05:14.444409Z","shell.execute_reply":"2022-01-02T22:05:15.213383Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Aumentar datos\ndef aumentar_datos(input_img,path_output):\n    Imagen = Image.open(input_img)\n    volteo_v = ImageOps.flip(Imagen)\n    volteo_v.save(path_output+\"_vflip\"+\".png\")\n    volteo_h = ImageOps.mirror(Imagen)\n    volteo_h.save(path_output+\"_hflip\"+\".png\")\n    \n    for angulo in range(30,345,30):\n        rotacion = Imagen.rotate(angulo)\n        rotacion.save(path_output+\"_\"+str(angulo)+\".png\")\n        volteo_v = ImageOps.flip(rotacion)\n        volteo_v.save(path_output+\"_\"+str(angulo)+\"_vflip\"+\".png\")\n        volteo_h = ImageOps.mirror(rotacion)\n        volteo_h.save(path_output+\"_\"+str(angulo)+\"_hflip\"+\".png\")\n        \n\ndef procesado(ids, clip=5, interpolacion=cv2.INTER_AREA, biopsia=True):\n    \n    path_img=\"../input/mias-mammography/all-mias/\"+ids+\".pgm\"\n    \n    img=cv2.imread(path_img,cv2.IMREAD_GRAYSCALE)\n    \n    cord_x, cord_y, radius, tipo = info.loc[ids,info.columns[4:8]]\n    \n    if tipo!=\"Normal\":\n        \n        if biopsia==True:\n            cord_x=int(cord_x)\n            cord_y=1024-int(cord_y)\n            radius=int((150/radius)*radius)\n            \n            inf_cord_y=cord_y-radius\n            sup_cord_y=cord_y+radius\n            inf_cord_x=cord_x-radius\n            sup_cord_x=cord_x+radius\n            \n            if sup_cord_y>1024:\n                inf_cord_y=inf_cord_y-(sup_cord_y-1024)\n                sup_cord_y=1024\n                \n            if inf_cord_y<0:\n                sup_cord_y=sup_cord_y+abs(inf_cord_y)\n                inf_cord_y=0\n                \n            if sup_cord_x>1024:\n                inf_cord_x=inf_cord_x-(sup_cord_x-1024)\n                sup_cord_x=1024\n                \n            if inf_cord_x<0:\n                sup_cord_x=sup_cord_x+abs(inf_cord_x)\n                inf_cord_x=0\n                \n            img2=img[inf_cord_y:sup_cord_y, inf_cord_x:sup_cord_x]\n        else:\n            blur = cv2.GaussianBlur(img,(5,5),0)\n            _, breast_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n            cnts, _ = cv2.findContours(breast_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            cnt = max(cnts, key = cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(cnt)\n            img2=img[y:y+h, x:x+w]       \n    else:\n        \n        blur = cv2.GaussianBlur(img,(5,5),0)\n        _, breast_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        cnts, _ = cv2.findContours(breast_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnt = max(cnts, key = cv2.contourArea)\n        x, y, w, h = cv2.boundingRect(cnt)\n               \n        if biopsia==True:\n            crop_img=img[y:y+h, x:x+w]\n            centro=(int(crop_img.shape[0]/2),int(crop_img.shape[1]/2))\n            img2=crop_img[(centro[0]-120):(centro[0]+120),(centro[1]-120):(centro[1]+120)]            \n        else:\n            img2=img[y:y+h, x:x+w]\n            \n    clahe = cv2.createCLAHE(clipLimit = clip)\n    cl = clahe.apply(np.array(img2, dtype=np.uint8))\n    cl=cv2.resize(cl,(224,224),interpolation = interpolacion)\n    img2=np.dstack([cl,cl,cl])\n    \n    return(img2)\n\nprint(\"Listo!!\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:29.432863Z","iopub.execute_input":"2022-01-02T22:05:29.433278Z","iopub.status.idle":"2022-01-02T22:05:29.455363Z","shell.execute_reply.started":"2022-01-02T22:05:29.433241Z","shell.execute_reply":"2022-01-02T22:05:29.454594Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def zoom(ids):\n    \n    \n    path_img=\"../input/mias-mammography/all-mias/\"+ids+\".pgm\"\n    \n    img=cv2.imread(path_img,cv2.IMREAD_GRAYSCALE)\n    \n    cord_x, cord_y, radius, tipo = info.loc[ids,info.columns[4:8]]\n    \n    biopsia=True\n    interpolacion=cv2.INTER_AREA\n    \n    \n    if tipo!=\"Normal\":\n        \n        if biopsia==True:\n            cord_x=int(cord_x)\n            cord_y=1024-int(cord_y)\n            radius=int((150/radius)*radius)\n            \n            inf_cord_y=cord_y-radius\n            sup_cord_y=cord_y+radius\n            inf_cord_x=cord_x-radius\n            sup_cord_x=cord_x+radius\n            \n            if sup_cord_y>1024:\n                inf_cord_y=inf_cord_y-(sup_cord_y-1024)\n                sup_cord_y=1024\n                \n            if inf_cord_y<0:\n                sup_cord_y=sup_cord_y+abs(inf_cord_y)\n                inf_cord_y=0\n                \n            if sup_cord_x>1024:\n                inf_cord_x=inf_cord_x-(sup_cord_x-1024)\n                sup_cord_x=1024\n                \n            if inf_cord_x<0:\n                sup_cord_x=sup_cord_x+abs(inf_cord_x)\n                inf_cord_x=0\n                \n            img2=img[inf_cord_y:sup_cord_y, inf_cord_x:sup_cord_x]\n\n    else:\n        \n        blur = cv2.GaussianBlur(img,(5,5),0)\n        _, breast_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        cnts, _ = cv2.findContours(breast_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnt = max(cnts, key = cv2.contourArea)\n        x, y, w, h = cv2.boundingRect(cnt)\n               \n        if biopsia==True:\n            crop_img=img[y:y+h, x:x+w]\n            centro=(int(crop_img.shape[0]/2),int(crop_img.shape[1]/2))\n            img2=crop_img[(centro[0]-120):(centro[0]+120),(centro[1]-120):(centro[1]+120)]            \n            \n    img2=cv2.resize(img2,(224,224),interpolation = interpolacion)\n    img2=np.dstack([img2,img2,img2])\n        \n    return(img2)\n\nprint(\"Listo!!\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:32.667083Z","iopub.execute_input":"2022-01-02T22:05:32.667769Z","iopub.status.idle":"2022-01-02T22:05:32.684489Z","shell.execute_reply.started":"2022-01-02T22:05:32.667732Z","shell.execute_reply":"2022-01-02T22:05:32.683488Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"ids=\"mdb005\"\n\nimagen_original=cv2.imread(\"../input/mias-mammography/all-mias/\"+ids+\".pgm\")\nimagen_zoom=zoom(ids)\nimagen_procesada=procesado(ids,biopsia=True,clip=2)\n\nfig=plt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nplt.imshow(imagen_original);\nplt.title(\"Original\")\n\nplt.subplot(1,3,2)\nplt.imshow(imagen_zoom)\nplt.title(\"Zoom\")\n\nplt.subplot(1,3,3)\nplt.imshow(imagen_procesada)\nplt.title(\"CLAHE\")\n\nplt.savefig('procesado.png')            \nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:35.609791Z","iopub.execute_input":"2022-01-02T22:05:35.610338Z","iopub.status.idle":"2022-01-02T22:05:36.569038Z","shell.execute_reply.started":"2022-01-02T22:05:35.610298Z","shell.execute_reply":"2022-01-02T22:05:36.568406Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Particiones\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(info_balanceado, test_size=0.5, random_state=42,stratify=info_balanceado.Tipo)\n\nprint(\"Listo!!!\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:46.211174Z","iopub.execute_input":"2022-01-02T22:05:46.211879Z","iopub.status.idle":"2022-01-02T22:05:46.923644Z","shell.execute_reply.started":"2022-01-02T22:05:46.211839Z","shell.execute_reply":"2022-01-02T22:05:46.922871Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(train.Tipo.value_counts(),\"\\n\")\nprint(test.Tipo.value_counts(),\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:54.085752Z","iopub.execute_input":"2022-01-02T22:05:54.086291Z","iopub.status.idle":"2022-01-02T22:05:54.094994Z","shell.execute_reply.started":"2022-01-02T22:05:54.086252Z","shell.execute_reply":"2022-01-02T22:05:54.093592Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"frec_A=train.Tipo.value_counts()\nfrec_B=test.Tipo.value_counts()\n\nfig=plt.figure(figsize=(12,5))\n\nplt.subplot(1,2,1)\n\nplt.bar(frec_A.index,frec_B.values)\nplt.title('Set Train: Distribución de imágenes',fontsize=15)\nplt.ylabel('Número de imágenes',fontsize=15)\nplt.xlabel('Categorías',fontsize=15)\n\nfor absoluto,categoria in zip(frec_A.values,range(2)):\n    pct=absoluto/frec_A.sum()*100\n    pct=round(pct,2)\n    plt.text(categoria-0.15,absoluto-8,str(pct)+'%',fontsize=12)\n    \nplt.subplot(1,2,2)\n\nplt.bar(frec_B.index,frec_B.values)\nplt.title('Set Test: Distribución de imágenes',fontsize=15)\n#plt.ylabel('Número de imágenes',fontsize=15)\nplt.xlabel('Categorías',fontsize=15)\n\nfor absoluto,categoria in zip(frec_B.values,range(2)):\n    pct=absoluto/frec_B.sum()*100\n    pct=round(pct,2)\n    plt.text(categoria-0.15,absoluto-8,str(pct)+'%',fontsize=12)\n    \nplt.savefig('Particiones.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:05:57.523969Z","iopub.execute_input":"2022-01-02T22:05:57.524231Z","iopub.status.idle":"2022-01-02T22:05:57.848105Z","shell.execute_reply.started":"2022-01-02T22:05:57.524197Z","shell.execute_reply":"2022-01-02T22:05:57.847424Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"### Aumentar datos\ndef aumentar_datos(input_img,path_output):\n    Imagen = Image.open(input_img)\n    volteo_v = ImageOps.flip(Imagen)\n    volteo_v.save(path_output+\"_vflip\"+\".png\")\n    volteo_h = ImageOps.mirror(Imagen)\n    volteo_h.save(path_output+\"_hflip\"+\".png\")\n    \n    for angulo in range(30,345,30):\n        rotacion = Imagen.rotate(angulo)\n        rotacion.save(path_output+\"_\"+str(angulo)+\".png\")\n        volteo_v = ImageOps.flip(rotacion)\n        volteo_v.save(path_output+\"_\"+str(angulo)+\"_vflip\"+\".png\")\n        volteo_h = ImageOps.mirror(rotacion)\n        volteo_h.save(path_output+\"_\"+str(angulo)+\"_hflip\"+\".png\")\n        \n\ndef procesado(ids, clip=5, interpolacion=cv2.INTER_AREA, biopsia=True):\n    \n    path_img=\"../input/mias-mammography/all-mias/\"+ids+\".pgm\"\n    \n    img=cv2.imread(path_img,cv2.IMREAD_GRAYSCALE)\n    \n    cord_x, cord_y, radius, tipo = info.loc[ids,info.columns[4:8]]\n    \n    if tipo!=\"Normal\":\n        \n        if biopsia==True:\n            cord_x=int(cord_x)\n            cord_y=1024-int(cord_y)\n            radius=int((150/radius)*radius)\n            \n            inf_cord_y=cord_y-radius\n            sup_cord_y=cord_y+radius\n            inf_cord_x=cord_x-radius\n            sup_cord_x=cord_x+radius\n            \n            if sup_cord_y>1024:\n                inf_cord_y=inf_cord_y-(sup_cord_y-1024)\n                sup_cord_y=1024\n                \n            if inf_cord_y<0:\n                sup_cord_y=sup_cord_y+abs(inf_cord_y)\n                inf_cord_y=0\n                \n            if sup_cord_x>1024:\n                inf_cord_x=inf_cord_x-(sup_cord_x-1024)\n                sup_cord_x=1024\n                \n            if inf_cord_x<0:\n                sup_cord_x=sup_cord_x+abs(inf_cord_x)\n                inf_cord_x=0\n                \n            img2=img[inf_cord_y:sup_cord_y, inf_cord_x:sup_cord_x]\n        else:\n            blur = cv2.GaussianBlur(img,(5,5),0)\n            _, breast_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n            cnts, _ = cv2.findContours(breast_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            cnt = max(cnts, key = cv2.contourArea)\n            x, y, w, h = cv2.boundingRect(cnt)\n            img2=img[y:y+h, x:x+w]       \n    else:\n        \n        blur = cv2.GaussianBlur(img,(5,5),0)\n        _, breast_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        cnts, _ = cv2.findContours(breast_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnt = max(cnts, key = cv2.contourArea)\n        x, y, w, h = cv2.boundingRect(cnt)\n               \n        if biopsia==True:\n            crop_img=img[y:y+h, x:x+w]\n            centro=(int(crop_img.shape[0]/2),int(crop_img.shape[1]/2))\n            img2=crop_img[(centro[0]-120):(centro[0]+120),(centro[1]-120):(centro[1]+120)]            \n        else:\n            img2=img[y:y+h, x:x+w]\n            \n    clahe = cv2.createCLAHE(clipLimit = clip)\n    cl = clahe.apply(np.array(img2, dtype=np.uint8))\n    cl=cv2.resize(cl,(224,224),interpolation = interpolacion)\n    img2=np.dstack([cl,cl,cl])\n    \n    return(img2)\n\nprint(\"Listo!!\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:06:05.296354Z","iopub.execute_input":"2022-01-02T22:06:05.296628Z","iopub.status.idle":"2022-01-02T22:06:05.318799Z","shell.execute_reply.started":"2022-01-02T22:06:05.296595Z","shell.execute_reply":"2022-01-02T22:06:05.316462Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"./Set/train/Normal/\")\nos.makedirs(\"./Set/train/Anomalo/\")\n\nos.makedirs(\"./Set/test/Normal/\")\nos.makedirs(\"./Set/test/Anomalo/\")\n\nfor ids in train.index:\n    img_procesada=procesado(ids,biopsia=True,clip=1)    \n    Tipo=info.loc[ids,:].Tipo\n    \n    cv2.imwrite(\"./temp.png\",img_procesada)\n        \n    if Tipo==\"Normal\":\n        aumentar_datos(\"./temp.png\",\"./Set/train/Normal/\"+ids)\n        \n    else:\n        aumentar_datos(\"./temp.png\",\"./Set/train/Anomalo/\"+ids)\n        \n    os.remove(\"./temp.png\")   \n\n\nfor ids in test.index:\n    img_procesada=procesado(ids, biopsia=True, clip=1)    \n    Tipo=info.loc[ids,:].Tipo\n    \n    if Tipo==\"Normal\":\n        cv2.imwrite(\"./Set/test/Normal/\"+ids+\".png\",img_procesada)\n        \n    else:\n        cv2.imwrite(\"./Set/test/Anomalo/\"+ids+\".png\",img_procesada)\n    \nprint(\"Listo!!!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir((\"./Set/train/Normal/\"))))\nprint(len(os.listdir((\"./Set/test/Normal/\"))))\n\nprint(len(os.listdir((\"./Set/train/Anomalo/\"))))\nprint(len(os.listdir((\"./Set/test/Anomalo/\"))))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:09:05.087879Z","iopub.execute_input":"2022-01-02T22:09:05.088135Z","iopub.status.idle":"2022-01-02T22:09:05.099010Z","shell.execute_reply.started":"2022-01-02T22:09:05.088106Z","shell.execute_reply":"2022-01-02T22:09:05.098284Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"##Ejemplo de rotaciones\nids=\"mdb021\"\nimagenes=[ i for i in os.listdir(\"./Set/train/Anomalo/\") if i.find(ids)>=0]\nimagenes=imagenes[0:10]\n\ni=1\nplt.figure(figsize=(15, 8))\nplt.suptitle('Data augmentation',y=0.92,fontsize=15)\nfor imagen in imagenes:\n    plt.subplot(2,5,i)\n    plt.imshow(plt.imread(\"./Set/train/Anomalo/\"+imagen))\n    i=i+1\nplt.savefig('Augmentation.png')\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:09:18.770735Z","iopub.execute_input":"2022-01-02T22:09:18.771179Z","iopub.status.idle":"2022-01-02T22:09:20.330200Z","shell.execute_reply.started":"2022-01-02T22:09:18.771143Z","shell.execute_reply":"2022-01-02T22:09:20.329420Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  \n\nfrom tensorflow.keras.layers import Flatten,Dense, Dropout, Activation, BatchNormalization\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras import Sequential, Model\n\ntrain_path='./Set/train/'\ntest_path='./Set/test/'\n\nprint(\"listo!!!\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:09:28.796188Z","iopub.execute_input":"2022-01-02T22:09:28.796783Z","iopub.status.idle":"2022-01-02T22:09:33.330218Z","shell.execute_reply.started":"2022-01-02T22:09:28.796732Z","shell.execute_reply":"2022-01-02T22:09:33.329331Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"resnet50 = tf.keras.applications.resnet50\n\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=resnet50.preprocess_input,\n    validation_split=1/4,\n    height_shift_range=0.1,\n    width_shift_range=0.1,\n    rotation_range=15)\n\ntrain_generator=train_datagen.flow_from_directory(\n    directory=train_path,\n    classes=[\"Normal\",\"Anomalo\"],\n    target_size = (224, 224), \n    shuffle=True,\n    subset=\"training\")\n\nval_generator=train_datagen.flow_from_directory(    \n    directory=train_path,\n    classes=[\"Normal\",\"Anomalo\"],\n    target_size = (224, 224), \n    shuffle=True,\n    subset=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T22:09:57.577997Z","iopub.execute_input":"2022-01-02T22:09:57.578282Z","iopub.status.idle":"2022-01-02T22:09:57.894956Z","shell.execute_reply.started":"2022-01-02T22:09:57.578250Z","shell.execute_reply":"2022-01-02T22:09:57.894090Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"Resnet = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224,3), pooling=\"max\")\n\nfrom keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n\nfor layer in Resnet.layers:\n    if layer.name.startswith('conv5'):\n        layer.trainable=True\n    else:\n        layer.trainable=False\n\n\nx = Resnet.output\nx = Flatten()(x)\nx = Dense(64,use_bias=False)(x)\nx = Activation('relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.55)(x)\n\nx = Dense(16,use_bias=False)(x)\nx = Activation('relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.55)(x)\npredictions = Dense(2, activation=\"softmax\")(x)\n\nmodel_resnet50 = Model(inputs=Resnet.inputs, outputs=predictions)\noptimizador=tf.keras.optimizers.Adam(learning_rate=1e-4)\nperdida=tf.keras.losses.CategoricalCrossentropy()\n\n\n\nmodel_resnet50.compile(optimizer=optimizador,loss=perdida,metrics=['accuracy',tf.keras.metrics.AUC(),recall_m])\n\ncheckpoint_cb = ModelCheckpoint(\"model_resnet50.h5\", monitor='val_accuracy',mode='max',save_best_only=True)\nearly_stopping_cb = EarlyStopping(patience=5,monitor='val_accuracy', mode='max',restore_best_weights=True)\n\nhistory = model_resnet50.fit(train_generator,\n                     epochs=100,\n                     validation_data=val_generator,\n                     callbacks=[checkpoint_cb,early_stopping_cb],verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics=history.history\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1,2,1)\nplt.plot(metrics['accuracy'])\nplt.plot(metrics['val_accuracy'])\nplt.title('accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\n    \nplt.subplot(1,2,2)\nplt.plot(metrics['loss'])\nplt.plot(metrics['val_loss'])\nplt.title('loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T12:58:40.527006Z","iopub.execute_input":"2021-12-10T12:58:40.527566Z","iopub.status.idle":"2021-12-10T12:59:06.558117Z","shell.execute_reply.started":"2021-12-10T12:58:40.527527Z","shell.execute_reply":"2021-12-10T12:59:06.557469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator=train_datagen.flow_from_directory(\n    directory=train_path,\n    classes=[\"Normal\",\"Anomalo\"],\n    target_size = (224, 224), \n    shuffle=False,\n    subset=\"validation\")\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score ,f1_score, confusion_matrix, classification_report\n\nprob_pred=model_resnet50.predict(val_generator)\nclas_pred=prob_pred.argmax(axis=1)\nclas_test=val_generator.classes\n\nprint(classification_report(clas_test,clas_pred))\n\n\najuste=accuracy_score(clas_test,clas_pred).round(4)\n\nmatriz_confusion=confusion_matrix(y_true=clas_test,\n                                  y_pred=clas_pred)\n\nprint(\"\\nAjuste del test : {}\".format(ajuste))\npd.DataFrame(matriz_confusion,\n             columns=val_generator.class_indices.keys(),\n             index=val_generator.class_indices.keys())","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:46:04.823042Z","iopub.execute_input":"2021-12-11T16:46:04.823741Z","iopub.status.idle":"2021-12-11T16:46:17.124386Z","shell.execute_reply.started":"2021-12-11T16:46:04.823699Z","shell.execute_reply":"2021-12-11T16:46:17.123559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(\n    preprocessing_function=resnet50.preprocess_input)\n\ntest_generator=test_datagen.flow_from_directory(\n    directory=test_path,\n    classes=[\"Normal\",\"Anomalo\"],\n    target_size = (224, 224), \n    shuffle=False)\n\nprob_pred=model_resnet50.predict(test_generator)\nclas_pred=prob_pred.argmax(axis=1)\nclas_test=test_generator.classes\n\n\najuste=accuracy_score(clas_test,clas_pred).round(4)\n\nmatriz_confusion=confusion_matrix(y_true=clas_test,\n                                  y_pred=clas_pred)\n\nprint(\"\\nAjuste del test : {}\".format(ajuste))\n\npd.DataFrame(matriz_confusion,\n             columns=test_generator.class_indices.keys(),\n             index=test_generator.class_indices.keys())","metadata":{"execution":{"iopub.status.busy":"2021-12-11T16:46:21.900623Z","iopub.execute_input":"2021-12-11T16:46:21.900909Z","iopub.status.idle":"2021-12-11T16:46:22.585229Z","shell.execute_reply.started":"2021-12-11T16:46:21.900865Z","shell.execute_reply":"2021-12-11T16:46:22.584475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvar\n\nmetrics=history.history\n\nimport pickle\n\nf = open(\"metrics_model_resnet50.pkl\",\"wb\")\npickle.dump(metrics,f)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T12:03:01.336419Z","iopub.execute_input":"2021-12-10T12:03:01.337136Z","iopub.status.idle":"2021-12-10T12:03:01.344075Z","shell.execute_reply.started":"2021-12-10T12:03:01.337099Z","shell.execute_reply":"2021-12-10T12:03:01.343246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cargar\n\npath=\"../input/resultados/model_resnet50.h5\"\nmodelo = tf.keras.models.load_model(path)\n\nimport pickle\npath='../input/resultados/metrics_model_resnet50.pkl'\nwith open(path, 'rb') as f:\n    metrics= pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(\n    preprocessing_function=resnet50.preprocess_input)\n\ntest_generator=test_datagen.flow_from_directory(\n    directory=test_path,\n    classes=[\"Normal\",\"Anomalo\"],\n    target_size = (224, 224), \n    shuffle=False)\n\nprob_pred=modelo.predict(test_generator)\n\npredicciones=pd.DataFrame(prob_pred,columns=[\"Prob_Normal\",\"Prob_Anomalo\"])\npredicciones[\"Clase_Observada\"]=test_generator.classes\npredicciones[\"Clase_Predicha\"]=prob_pred.argmax(axis=1)\npredicciones[\"rutas\"]=test_generator.filepaths","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = tf.keras.preprocessing.image.img_to_array(img)\n    array = np.expand_dims(array, axis=0)\n    return array\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # Primero, creamos un modelo que asigna la imagen de entrada las activaciones de la última capa de conv, \n    # así como a las predicciones de salida.\n\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Luego, calculamos el gradiente de la clase predicha superior para nuestra imagen de entrada \n    # con respecto a las activaciones de la última capa de conv.\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # Este es el gradiente de la neurona de salida (superior predicha o elegida) \n    # con respecto al mapa de características de salida de la última capa de conv.\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # Este es un vector donde cada entrada es la intensidad media del gradiente \n    # sobre un canal de mapa de características específico\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # Multiplicamos cada canal en la matriz del mapa de características por \"qué tan importante es este canal\" \n    # con respecto a la clase predicha superior y luego sumamos todos los canales \n    # para obtener la activación de la clase del mapa de calor.\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # Para fines de visualización, también normalizaremos el mapa de calor entre 0 y 1\n    \n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef display_gradcam(img_path, heatmap, alpha=0.4):\n\n\n    img = tf.keras.preprocessing.image.load_img(img_path)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n\n    heatmap = np.uint8(255 * heatmap)\n\n    jet = cm.get_cmap(\"jet\")\n\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    return(superimposed_img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seleccion=predicciones.loc[(predicciones.Clase_Observada==predicciones.Clase_Predicha) & (predicciones.Clase_Observada==1),:].sort_values(by=\"Prob_Anomalo\",ascending=False)\nseleccion","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path=seleccion.rutas.values[1]\nprob=seleccion.Prob_Anomalo.values[1]\n\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Anómalo\\nClase Predicha: Anómalo ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path=seleccion.rutas.values[24]\nprob=seleccion.Prob_Anomalo.values[24]\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Anómalo\\nClase Predicha: Anómalo ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path=seleccion.rutas.values[44]\nprob=seleccion.Prob_Anomalo.values[44]\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Anómalo\\nClase Predicha: Anómalo ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seleccion=predicciones.loc[(predicciones.Clase_Observada==predicciones.Clase_Predicha) & (predicciones.Clase_Observada==0),:].sort_values(by=\"Prob_Normal\",ascending=False)\nseleccion","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path=seleccion.rutas.values[2]\nprob=seleccion.Prob_Normal.values[2]\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Normal\\nClase Predicha: Normal ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path=seleccion.rutas.values[13]\nprob=seleccion.Prob_Normal.values[13]\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Normal\\nClase Predicha: Normal ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seleccion=predicciones.loc[(predicciones.Clase_Observada!=predicciones.Clase_Predicha) & (predicciones.Clase_Observada==1),:].sort_values(by=\"Prob_Normal\",ascending=False)\nseleccion","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path=seleccion.rutas.values[0]\nprob=seleccion.Prob_Normal.values[0]\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Anómalo\\nClase Predicha: Normal ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seleccion=predicciones.loc[(predicciones.Clase_Observada!=predicciones.Clase_Predicha) & (predicciones.Clase_Observada==0),:].sort_values(by=\"Prob_Anomalo\",ascending=False)\nseleccion","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mg_path=seleccion.rutas.values[0]\nprob=seleccion.Prob_Anomalo.values[0]\nprob=np.round(prob*100,2)\nimg_size=(224,224)\nimg_array = resnet50.preprocess_input(get_img_array(img_path, size=img_size))\nlast_conv_layer_name=\"conv5_block3_out\"\n\nplt.figure(figsize=(9, 10))\nplt.suptitle(\"Clase Observada: Normal\\nClase Predicha: Anómalo ({p}%)\".format(p=prob),y=0.75,size=15)\n\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=0)\nplt.subplot(1,2,1)\nplt.title(\"Mapa Características clase Normal\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nheatmap = make_gradcam_heatmap(img_array, modelo, last_conv_layer_name, pred_index=1)\nplt.subplot(1,2,2)\nplt.title(\"Mapa Características clase Anómala\")\nplt.imshow(display_gradcam(img_path, heatmap,alpha=0.2))\nplt.axis('off')\nplt.savefig('heatmap_1.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}
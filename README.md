# Técnicas de explicabilidad aplicadas en Redes Convolucionales para el diagnóstico por  imagen del cáncer de mama

En la actualidad, las Redes Neuronales Convolucionales, o CNN por sus siglas en inglés, gozan de gran relevancia en la disciplina de Deep Learning a la hora de trabajar con imágenes  por su gran eficacia en tareas como detección de objetos y reconociendo patrones en imágenes. Pero a pesar de los prometedores resultados de las CNN tienen un gran handicap, y es la falta de interpretabilidad para un humano. Esto es debido a la gran cantidad de parámetros a estimar entre sus numerosas capas que forman su arquitectura, que hace que el conocimiento no quede en nuestras manos, sino codificado dentro de la propia red. Esta opacidad o falta de transparencia limita su aplicación práctica pese a su gran rendimiento en numerosos problemas reales.

Por lo tanto, el propósito de este trabajo es estudiar y analizar Grad-CAM, una técnica de visualización de neuronas que permite explicar hacia donde está "mirando" una arquitectura convolucional. 

El producto resultante de este estudio es un pipeline con el que se obtiene modelo de red convolucional de arquitectura ResNet que ha sido entrenado con un set de imágenes clínicas compuesto por mamografías, y que es capaz de obtener un ajuste del 92% en su tarea de clasificar tejido mamario normal y tejido anómalo. Finalmente y por medio de la aplicación de Grad-CAM y de mapas de calor, se valida que las decisiones tomadas  por la red se fundamentan en secciones densas del tejido mamario identificando así el tumor.
